---
layout: slide
title: ""
---

# Future research directions #2

<div markdown="1" style="font-size:2vw">

- Two (or three?) possible ways to make the NN deal with temporal information:
	- **3D ResNets** - [Would Mega-scale Datasets Further Enhance Spatiotemporal 3D CNNs? (2020)](https://arxiv.org/abs/2004.04968){: .pleaseletmeclickonthislink5px}
	- **CNN+LSTM** - [Beyond Short Snippets: Deep Networks for Video Classification (2015)](https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Ng_Beyond_Short_Snippets_2015_CVPR_paper.html){: .pleaseletmeclickonthislink5px}
	- **Vision Transformers?**
		- [An Image Is Worth 16x16 Words: Transformers For Image Recognition At Scale](https://openreview.net/pdf?id=YicbFdNTTy){: .pleaseletmeclickonthislink5px}
		- [An Image is Worth 16x16 Words, What is a Video Worth? (pre-published on 25 Mar 2021)](https://arxiv.org/abs/2103.13915){: .pleaseletmeclickonthislink5px}
- Currently working on:
	- [3D-ResNet-50-KMS](https://github.com/kenshohara/3D-ResNets-PyTorch){: .pleaseletmeclickonthislink5px}
		- pretrained on Kinetics-700 (K), Moments in Time (M), STAIR-Actions (S)

</div>

[![resnet-3d-training-round-2](assets/pics/old-imgs/3d-resnet/resnet-3d-50-show-batch.png){: .resultsimage height="45%" width="45%"}](assets/pics/old-imgs/3d-resnet/resnet-3d-50-show-batch.png){: .pleaseletmeclickonthislink}

<!-- figcaption class="figcaption" markdown="1">

Credits: [SFINGE 3D: A novel benchmark for online detection and recognition of heterogeneous hand gestures from 3D fingersâ€™ trajectories](https://www.sciencedirect.com/science/article/pii/S0097849320301163){: .pleaseletmeclickonthislink}

</figcaption -->

